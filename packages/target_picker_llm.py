from __future__ import annotations
from typing import Optional, Dict, Any
import json
import pandas as pd
from .schema_utils import Schema, ColumnSchema
from config.llm_client import get_openai_client, MODEL
from openai import RateLimitError, APIError, APITimeoutError, OpenAIError
from .retry_utils import retry_with_backoff

def _schema_summary_for_llm(schema: Schema, max_cols: int = 60, max_name_len: int = 60) -> str:
    """Buduje czytelne podsumowanie schematu dla LLM"""
    lines = []
    for i, (name, col) in enumerate(schema.columns.items()):
        if i >= max_cols:
            lines.append(f"... (+{len(schema.columns)-max_cols} more)")
            break
        short = (name[:max_name_len] + "â€¦") if len(name) > max_name_len else name
        lines.append(
            f"- {short} | type={col.semantic_type} | n_unique={col.n_unique} | "
            f"missing_ratio={col.missing_ratio:.2f} | is_unique={col.is_unique} | is_constant={col.is_constant}"
        )
    return "\n".join(lines)

def _build_prompt(schema: Schema, df_rows: int) -> str:
    """Buduje prompt dla LLM"""
    return (
        "Kontekst danych:\n"
        f"- liczba wierszy: {df_rows}\n"
        f"- liczba kolumn: {len(schema.columns)}\n"
        "- kolumny (skrÃ³t):\n"
        f"{_schema_summary_for_llm(schema)}\n\n"
        "Zadanie:\n"
        "Wybierz NAJLEPSZÄ„ pojedynczÄ… kolumnÄ™ docelowÄ… do modelowania ML (regresja/klasyfikacja).\n"
        "Kryteria:\n"
        "- NIE wybieraj kolumn typu datetime/unknown, ID, staÅ‚ych ani o 1 unikalnej wartoÅ›ci\n"
        "- Preferuj kolumny o sensownej liczbie unikalnych wartoÅ›ci\n"
        "- Unikaj kolumn z duÅ¼Ä… liczbÄ… brakÃ³w\n"
        "- JeÅ›li nazwa sugeruje cel (np. churn, price, label, target), to duÅ¼y plus\n\n"
        "WAÅ»NE: ZwrÃ³Ä‡ WYÅÄ„CZNIE czysty JSON bez dodatkowych formatowaÅ„ lub blokÃ³w kodu!\n"
        'Format: {"target": "nazwa_kolumny", "confidence": 0.85, "reason": "powÃ³d wyboru"}\n'
        "gdzie confidence to wartoÅ›Ä‡ 0.0-1.0, a target to dokÅ‚adna nazwa kolumny z listy powyÅ¼ej.\n"
        "NIE uÅ¼ywaj ```json``` ani innych oznaczeÅ„ markdown!"
    )

def llm_guess(df: pd.DataFrame, schema: Schema, api_key: str = None) -> Optional[str]:
    """
    WywoÅ‚uje model OpenAI i prÃ³buje wskazaÄ‡ kolumnÄ™ targetu.
    Zwraca nazwÄ™ kolumny lub None.
    """
    # SprawdÅº czy dostÄ™pny jest klucz API
    if not api_key:
        print("âŒ [LLM] Brak klucza API OpenAI - pomijam zapytanie LLM")
        return None
    
    # UtwÃ³rz klienta z podanym kluczem
    client = get_openai_client(api_key)
    if client is None:
        print("âŒ [LLM] Nie moÅ¼na utworzyÄ‡ klienta OpenAI")
        return None
    
    print("ğŸ¤– [LLM] Rozpoczynam zapytanie do LLM o wybÃ³r kolumny docelowej...")
    
    if df is None or df.shape[1] == 0:
        print("âŒ [LLM] Brak danych - nie moÅ¼na wykonaÄ‡ zapytania")
        return None

    prompt = _build_prompt(schema, df_rows=df.shape[0])
    
    print(f"ğŸ” [LLM] AnalizujÄ™ {len(schema.columns)} kolumn w {df.shape[0]} wierszach...")
    
    def _call_llm():
        print("ğŸ“¡ [LLM] WysyÅ‚am zapytanie do OpenAI...")
        
        # Poprawione API call - uÅ¼ywamy chat completions
        response = client.chat.completions.create(
            model=MODEL,
            messages=[
                {
                    "role": "system", 
                    "content": (
                        "JesteÅ› asystentem danych. Na podstawie listy kolumn z metadanymi wybierz "
                        "NAJLEPSZÄ„ kolumnÄ™ docelowÄ… (target do modelowania). "
                        "ODPOWIADAJ WYÅÄ„CZNIE czystym JSON bez formatowania markdown!"
                    )
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=300,
            timeout=20
        )
        return response

    try:
        print("â³ [LLM] Oczekiwanie na odpowiedÅº...")
        
        response = retry_with_backoff(
            func=_call_llm,
            exceptions=(RateLimitError, APIError, APITimeoutError, OpenAIError),
            max_retries=3,  # Zmniejszamy liczbÄ™ prÃ³b
            base_delay=2.0,  # ZwiÄ™kszamy opÃ³Åºnienie
            max_delay=30.0,
        )
        
        # WyciÄ…gnij content z odpowiedzi
        content = response.choices[0].message.content.strip()
        print(f"ğŸ“¥ [LLM] Otrzymano odpowiedÅº: {content}")
        
        # WyczyÅ›Ä‡ content z markdown blokÃ³w kodu
        if content.startswith("```json"):
            content = content.replace("```json", "").replace("```", "").strip()
        elif content.startswith("```"):
            content = content.replace("```", "").strip()
        
        print(f"ğŸ§¹ [LLM] Oczyszczona odpowiedÅº: {content}")
        
        # SprÃ³buj sparsowaÄ‡ JSON
        try:
            data = json.loads(content)
            print(f"âœ… [LLM] Sparsowano JSON: {data}")
        except json.JSONDecodeError as e:
            print(f"âŒ [LLM] BÅ‚Ä…d parsowania JSON: {e}")
            print(f"Raw content: {content}")
            # SprÃ³buj wyciÄ…gnÄ…Ä‡ JSON z tekstu uÅ¼ywajÄ…c regex jako backup
            import re
            json_pattern = r'\{[^{}]*\}'
            matches = re.findall(json_pattern, content)
            if matches:
                try:
                    data = json.loads(matches[0])
                    print(f"âœ… [LLM] Sparsowano JSON przez regex: {data}")
                except:
                    return None
            else:
                return None
        
        candidate = data.get("target")
        confidence = data.get("confidence", 0.0)
        reason = data.get("reason", "Brak powodu")
        
        print(f"ğŸ¯ [LLM] Sugerowana kolumna: '{candidate}' (confidence: {confidence:.2f})")
        print(f"ğŸ’­ [LLM] PowÃ³d: {reason}")
        
        # Walidacja kandydata
        if not candidate:
            print("âŒ [LLM] Brak sugestii kolumny")
            return None
            
        if candidate not in df.columns:
            print(f"âŒ [LLM] Kolumna '{candidate}' nie istnieje w danych")
            available_cols = list(df.columns)[:10]  # pokaÅ¼ pierwszych 10
            print(f"DostÄ™pne kolumny (prÃ³bka): {available_cols}")
            return None
        
        # SprawdÅº jakoÅ›Ä‡ kandydata
        col: ColumnSchema = schema.columns[candidate]
        
        if col.is_constant:
            print(f"âŒ [LLM] Kolumna '{candidate}' jest staÅ‚a")
            return None
            
        if col.n_unique < 2:
            print(f"âŒ [LLM] Kolumna '{candidate}' ma mniej niÅ¼ 2 unikalne wartoÅ›ci")
            return None
            
        if col.semantic_type in {"datetime", "unknown"}:
            print(f"âŒ [LLM] Kolumna '{candidate}' ma niewÅ‚aÅ›ciwy typ: {col.semantic_type}")
            return None
        
        print(f"âœ… [LLM] Kolumna '{candidate}' przeszÅ‚a walidacjÄ™!")
        print(f"ğŸ“Š [LLM] SzczegÃ³Å‚y: type={col.semantic_type}, unique={col.n_unique}, missing={col.missing_ratio:.2%}")
        
        return candidate
        
    except RateLimitError as e:
        print(f"âŒ [LLM] BÅ‚Ä…d limitu zapytaÅ„ (429): {e}")
        print("ğŸ’¡ [LLM] SprÃ³buj ponownie za kilka minut lub sprawdÅº limit API")
        return None
    except APIError as e:
        if hasattr(e, 'status_code') and e.status_code == 429:
            print(f"âŒ [LLM] BÅ‚Ä…d limitu zapytaÅ„ (429): {e}")
            print("ğŸ’¡ [LLM] SprÃ³buj ponownie za kilka minut lub sprawdÅº limit API")
        else:
            print(f"âŒ [LLM] BÅ‚Ä…d API: {e}")
        return None
    except APITimeoutError as e:
        print(f"âŒ [LLM] Timeout API: {e}")
        print("ğŸ’¡ [LLM] SprÃ³buj ponownie za chwilÄ™")
        return None
    except OpenAIError as e:
        print(f"âŒ [LLM] BÅ‚Ä…d OpenAI: {e}")
        return None
    except Exception as e:
        print(f"âŒ [LLM] Nieoczekiwany bÅ‚Ä…d: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()
        return None